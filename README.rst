DeepSpeech master Examples
==========================

These are various examples on how to use or integrate DeepSpeech using our packages.

It is a good way to just try out DeepSpeech before learning how it works in detail, as well as a source of inspiration for ways you can integrate it into your application or solve common tasks like voice activity detection (VAD) or microphone streaming.

Contributions are welcome!

**Note:** These examples target DeepSpeech **master branch** only. If you're using a different release, you need to go to the corresponding branch for the release:

* `v0.7.x <https://github.com/mozilla/DeepSpeech-examples/tree/r0.7>`_
* `v0.6.x <https://github.com/mozilla/DeepSpeech-examples/tree/r0.6>`_
* `master branch <https://github.com/mozilla/DeepSpeech-examples/tree/master>`_

**List of examples**

Python:
-------

* `Microphone VAD streaming  <mic_vad_streaming/README.rst>`_
* `VAD transcriber  <vad_transcriber/>`_
* `Websocket-based server <python_websocket_server/>`_

JavaScript:
-----------

* `FFMPEG VAD streaming  <ffmpeg_vad_streaming/README.MD>`_
* `Node.JS microphone VAD streaming <nodejs_mic_vad_streaming/Readme.md>`_
* `Node.JS wav <nodejs_wav/Readme.md>`_
* `Web Microphone Websocket streaming <web_microphone_websocket/Readme.md>`_
* `Electron wav transcriber <electron/Readme.md>`_

C#/.NET:
--------

* `.NET framework <net_framework/>`_

Java/Android:
-------------

* `mozilla/androidspeech library <https://github.com/mozilla/androidspeech/>`_