DeepSpeech master Examples
==========================

These are various examples on how to use or integrate DeepSpeech using our packages.

It is a good way to just try out DeepSpeech before learning how it works in detail, as well as a source of inspiration for ways you can integrate it into your application or solve common tasks like voice activity detection (VAD) or microphone streaming.

Contributions are welcome!

**Note:** These examples target DeepSpeech **master branch** only. If you're using a different release, you need to go to the corresponding branch for the release:

* `v0.8.x <https://github.com/mozilla/DeepSpeech-examples/tree/r0.8>`_
* `v0.7.x <https://github.com/mozilla/DeepSpeech-examples/tree/r0.7>`_
* `v0.6.x <https://github.com/mozilla/DeepSpeech-examples/tree/r0.6>`_
* `master branch <https://github.com/mozilla/DeepSpeech-examples/tree/master>`_

**List of examples**

Python:
-------

* `Microphone VAD streaming <mic_vad_streaming/README.rst>`_
* `VAD transcriber <vad_transcriber/>`_

JavaScript:
-----------

* `FFMPEG VAD streaming <ffmpeg_vad_streaming/README.MD>`_
* `Node.JS microphone VAD streaming <nodejs_mic_vad_streaming/Readme.md>`_
* `Node.JS wav <nodejs_wav/Readme.md>`_
* `Web Microphone Websocket streaming <web_microphone_websocket/Readme.md>`_
* `Electron wav transcriber <electron/Readme.md>`_

Windows/C#:
-----------

* `.NET framework <net_framework/>`_
* `Universal Windows Platform (UWP) <uwp/>`_.

Java/Android:
-------------

* `mozilla/androidspeech library <https://github.com/mozilla/androidspeech/>`_

Nim:
----

* `nim_mic_vad_streaming <nim_mic_vad_streaming/README.md>`_.
